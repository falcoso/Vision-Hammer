10/10/19 - First Supervision

  First meeting with Joan. Discussed initial Risk assessment. Games workshop are
  unable to provide CAD models for training, but JL will contact Hugo in the
  dept who has been working on voxel carving to potentially scan in models. Need
  to bring in models next week to show, as well as start making some cardboard
  models of scenery to work with.

  Further work:
  python-pcl may be a useful point cloud library. Look into registration using
  ICP in the open3d library. A lot of mention of mixture of gaussians.

11/10/19 - Cameras

  Prices of the Realsense can vary upwards of £150, although a second hand
  v2 Kinect can go for as little as £40, comparisons online show less resolution
  with the kinect but much fewer noise artefacts and therefore a clearer point
  cloud image.

  Kinect v2: 0.5m-4.5m
  RealSense: 0.2-1.2m

15/10/19

Created a set of several related point clouds to try registering with open3d.
  Global method uses RASNAC and then refines to a more accurate registration
  with ICP. However, matching doesn't seem very good out the box even with what
  appears to be very similar clouds.

  Created CAD model for a building that can be laser cut to start creating a
  board top from which to produce LOS.

18/10/19 - Registration works!

  https://towardsdatascience.com/point-cloud-data-simple-approach-f3855fdc08f5
  Created some cleaner point clouds which are simply models on a table with
  blinds in the background. This makes registration a much simpler task. Also
  looked at Coloured Point Cloud Registration Revisited which makes use of the
  fact that we have a colour image to overlay. Now need to look into how I can
  automatically clean up the data by removing outliers.

  Have done some reading on further registration techniques, the mention of GMM
  models basically involves clustering GMMs at different levels of hierarchy.
  The mean of each cluster tells you its location and the variance matrix give
  the shape i.e. an eigenvalue close to 0 means that the cluster is likely a
  plane.

  Created a simple script that tries to bin the most common normals in a scene.
  Doesn't actually produce perfect normals to the large planes in the point
  clouds but, may be useful as a finger print to work out initial rotations.

23/10/19 - Isolating models
  Demonstrated current matching. discussed once models have been isolated
  looking at PCA of each model to get a unique signature. Other matching
  criteria might be volume, and elevation of centre of mass from the ground.

  TODO:
  Make a set of images RGB with depth info and will look at voxel carving, try
  matching the clouds together to get an isolated mesh of each model, Hugo
  will also look into the dataset to see what he can do with them.
  Clear out planes, and try matching the point clouds with just the structure
  of the miniatures remaining.

28/10/19 - Isolating Planes
  Successfully implemented a region growing algorithm and have been able to
  isolate planes. Created ipython notebook to make displaying segments of code
  much easier.

6/11/19
  Over the last week have created data set for each model to be stitched
  together as well as additional images of the board states. After cleaning up
  the individual models, removing all the background and scatter etc. (which
  works remarkably well!) the point cloud registration is very poor, and in fact
  makes the alignment worse. I have begun looking at a potential new algorithm
  that treats colour as extra spatial dimensions for working out correspondence.
  Have also considered forcing a large known plane into the point cloud to help
  anchor the cloud.

  bi-vector

  cost function base on point normals

  cut out all but legs

  nerbs

12/11/19
  Fine tuning the registration algorithm and forcing in the table planes does
  cause some of the clouds to register correctly, however outliers in the plane
  fitting causes some of the initial alignment to be off. Currently looking at
  Hough transforms and RANSAC to more reliably fit the planes.

  Upon testing an example where the plane fit is poor I noticed that the SVD
  with smallest eigen value is different to pseudoinverse result - looking in
  to whether this is to do with small coordinate system so will play around
  with scaling

19/11/19
  Turns out there was nothing wrong with the plane fitting but SVD was used
  since all the principle vectors were required later on so no point
  re-computing.

  Created the combined meshes of the models using CloudCompare and aligning them
  by hand. Have a full model of the Broadside and Commander but its very noisy
  so trying to create a mesh from them is hard. Ball Pivoting algorithm seems
  to provide good results, but it occasionally flips to internal surfaces which
  we don't want!

  Also found that open3d does have a voxel carving method based on depth images
  so that may be worth looking into should this fail.


  you know the minimum size of models so can detect point clouds that are not models or parts of models from This

03/01/19
    While writing the report it was noticed that in the segmentation function
    the input cloud is never reduced so there may be extensive repetition of
    calculations - this might be why it runs so slow on non-downsampled clouds

05/01/19
    Segmentation still runs quite slowly so may be worth looking at other options
    Previously a link to a clustering tutorial was used. Will look at this.

26/01/19
    Improved segmentation with DBSCAN - planes are removed from a scene and then
    clustered for region proposals. There is an open3d implementation of this
    but if this gets harder on larger scenes, the sklearn DBSCAN has
    parallelisation which may speed things up.

    Another two reference models have been made. AliceVision outputs a .obj file
    with a .mtl which is proving strangely difficult to convert to a .ply that
    has colour. For now it may be worth registering using the point cloud output
    of MeshRoom which does have colour combined, but some of the references may
    be patchy.

    Have tested the algorithm on the board scenes and even without registering
    the table is isolated very effectively.

28/01/20
    Have updated how the table section is isolated, in case the view of the
    floor in a scene is quite large. instead of just finding the largest plane
    the program will instead find the common floor direction vector and then
    find the plane closest to that direction.

4/02/20
    The segmentation is able to isolate everything on or above the table, and
    align the table normal with the y-axis. Segmentation is then able to
    pick out the model clusters as well as the building with models in it so
    the focus has been to try and then extract the models from within the
    building as we as reduce the dimensionality of the building (since it is
    effectively a cut up box)

    Following meeting on 31/1/20 the main focus has been to see whether a
    histogram of the normals of the scenery item might produce the normals
    since the normals of the models in the building could be considered noise.
    Two approaches were taken, first just putting all the point normals into the
    histogram, second region growing planes in the cluster and then putting
    those normals into the histogram. While something close to the building axis
    are produced, they are not consistent enough between models.

    Since the y-axis of the model has already been found, a minimum bounding box
    in the plane of the x-z axis should reduce be axis aligned with the walls.
    https://geidav.wordpress.com/2014/01/23/computing-oriented-minimum-bounding-boxes-in-2d/
    https://stackoverflow.com/questions/32892932/create-the-oriented-bounding-box-obb-with-python-and-numpy
    https://www.sciencedirect.com/topics/computer-science/oriented-bounding-box

7/02/20
    Created algorithm that fits 2 perpendicular lines in a set of data in a form
    of pseudo clustering/regression. The maths shown in written notes gives a
    least squared solution for 1 line and then a scalar parameter that is used
    to fit the other.

    It seems odd that the vector direction ignores half of the points? Since it
    only uses least squares for one of the lines it could be improved by doing a
    RANSAC fit to that one line then calculate alpha as before to make it more
    robust to outliers. Now moving on to testing on more examples.

    Discovered for some lower angle point clouds the background is not
    effectively removed from the main scene. Looking into clustering the table
    plane and bounding box the largest section.

10/02/20
    The algorithm runs with limited success. The line allocation can definitely
    be improved since we know its a corner we are looking for but its difficult
    to characterise the selection in a clear way. The current solution may
    potentially blow up if the line passes through the origin, but efforts to
    re-formulate the problem using Lagrange multipliers has reached a brick wall
    so checks on the solution need to be made. Similar efforts have also been
    made in using homogenous coordinates.

11/02/20
    Have focussed on the RANSAC implementation and have been able to achieve
    much more robust results on all the samples provided. Can now move to making
    use of this to align the clouds closer.

18/02/20
    Over the last week have been able to align all the clouds - the corner
    finding provides an excellent initial global alignment with ICP can fine
    tune. One of the clouds does keep appearing in the opposite quadrant so have
    excluded that for now until I can sort out the return vector convention
    fully.

    Cropped down reference models and started working on sorting out an initial
    orientation from which we can introduce the matching of the models.


    check for ray marching, check threshold with proximity to points

21/02/20
    Fixed the orientation errors with one of the clouds. Global alignment is
    very good, but to fine tune the ICP it needs to be done in a specific order
    to work.

24/02/20
    Have implemented basic matching, carrying out ICP at 20 different initial
    rotations about the origin. Digging deeper into the algorithm is appears
    the odd angles are coming from a large number of points being considered
    outliers so need to look into a way of fixing this. Scaling is currently
    only implemented in the point to point algorithm, but this just shrinks
    the cluster down very small and moves it to a dense section which isn't
    helpful.

25/02/20
    Adding in floor plane doesn't seem to help with the registration for
    matching. Have derived a potential expression for a constrained ICP that
    will only allow translation and rotation about the y axis

26/02/20
    Had some issues with getting the maths to work for point to plane
    constrained ICP, but point to point has a simply solution from the Procrustes
    problem. The solution can be created by taking the SVD of the x and z
    coordinates of the target points and the fit is remarkably good in some
    cases. Now just need to play around with different initialisations, and then
    it should be easy to cost up and work out what fits best.

3/03/20
    Tried experimenting with hard coding in the scaling to see if that improves
    the fit results. From recognising the building the scale is determined but
    the height of the other clusters doesn't seem to accurately match as well.

4/03/20
    Adding in outlier detection has greatly improved fit - cost function drops
    by several orders of magnitude despite still using 90% of points in the
    segmented cluster. The correct models have the best fit now, but depending
    on whether hard scaling is used or not the actual transformation angle can
    vary a lot.

5/03/20
    Added optimisation of the y translation. This provides much better
    differentiation between right and wrong cost function, but fit could still
    be more robust. Have found derivations of point to plane solution, but
    adding complete 3DOF in the translation gives near-perfect results so hasn't
    been implemented.

8/03/20
    Created self-contained classes for processing the scene and easily accessing
    models once they have been classified. Began looking at how to project the
    Triangle meshes into a 2D image view to get the view-point of the model and
    then calculate LOS.

2/04/20
    Gathered clouds for a new scene layout with all the models separate from the
    building so that the algorithm can be tested on matching all the models.
    Have also cut out the table plane of the reference models to reduce the
    bounding box size.

    Global alignment works just as well, but the constrained y axis rotation
    icp gives perfect alignment, where the significantly quicker library
    implementation throws away the initial alignment.

3/04/20
    Will experiment with using cluster height rather than bounding box volume,
    as it appears much of the variation and noise in the clustered model is
    in the x-z plane. If this still doesn't work, a penalisation to any height
    discrepancy in the icp cost function could be added as this will be better
    satisfied with closer-height matching models. Using height also has the
    bonus of sorting wide and thin clusters.

    The results make sure that 3/4 models in the new scene are matched with the
    incorrect model at least matching with the correct category of model (large
    or small). Will add in a separate volume check to filter out long thin
    sections also.

    A lot of the clusters in this new scene are clearly mis-coloured or are
    artefacts from the table. Will look at how potentially using a colour
    histogram to help filter noise could be used, since the material files are
    .png so can also be easily processed for matching.

6/04/20
    Looking at the histograms of the reference files vs the clouds, there is not
    enough data to accurately match the histograms with one another. It was
    also noted that the 'table' points in the clusters which were the wrong
    colour could still feasibly be in a structurally correct location on the
    model and therefore still useful for matching the models, since colour is
    not currently used in our constrained algorithm.

    May take new scene but make sure accuracy settings are turned up on the
    camera vs density - while the final clusters of the smaller models look
    largely unrecognisable (though still surprisingly match correct) it is
    possible to see the model structure in the individual scenes that make up
    the model, such as the protruding gun barrels.

    https://stackoverflow.com/questions/19000096/match-3d-point-cloud-to-cad-model

7/04/20
    When there is enough information in the sub-scenes for the model to match
    correctly, the sub-scene orientation is perfect. However there is often
    not enough points for it to be able to find any match, and none of them
    correctly identify the commander. It looks like the problem is often the
    surface just sits in the centre of the broadside reference, and because
    it is the surrounded by points it results in a lower cost.

    Playing around with the effects of point-to-plane instead.

8/04/20
    Have created some new scene layouts, captured both in the conventional way
    of using the RealSense and registering them, as well as photogrammetry on
    the views to validate on more 'accurate' data. Discovered also sampling
    triangle meshes on a Poisson disk - this could be helpful in specifically
    locating the building in a scene, and may allow for models internally to
    be taken out.

9/04/20
    Point to plan implemented. It runs at least 5x faster than point to point
    which may be down to the numpy least squares solver being more efficient
    than the svd. It is also much more consistent in its results, providing
    much tighter alignments which classify correctly! This faster alignment
    also means that the building can be explicitly matched to within a scene
    in a practical time-frame. Can look at isolating models within a building
    now.

10/04/20
    Created function that finds the circle of the base of the model, this can
    then be used to work out distances between models in a scene. Had to
    re-calculate all the transformation matrices for the references models as
    the .npy files got corrupted, but have now save all the models with that
    transformation applied so shouldn't be an issue again.

    The inferred radii of the bases show a maximum 2% error in the scaling. This
    could potentially be used as prior information to get more accurate scaling
    values

11/04/20
    Looked into improving correspondence in point to plane, by finding say 30
    nearest points and then matching normals but this greatly slowed down the
    algorithm without improving the matches or convergence that much. Largely,
    this will be down to the fact that more of the correspondence function then
    has to be implemented in python, and not necessarily it converging slower.

    Fit corner was made more robust by initialising the vector based on a line
    fit for all the points. The classification was also tweaked to take into
    account the fact the points form a corner rather than 2 perpendicular lines.

13/04/20
    Realised that the RANSAC regressor used to fit the model uses f(x)-y to
    classify inliers rather than a geometric distance.
    The following improvements have been made:
    - Geometric RANSAC regressor rather than the OLS RANSAC from scikitlearn to
      fit the lines
    - Threshold for inliers set at fixed value to tighten matches rather than
      use MADS
    - Fixed error in 1d RANSAC to maximise the number of inliers.
    - Classification is done by bisecting the points with a line at 45 degrees.
      This is done at both +ve and -ve 45 degrees, prioritising similarly
      sized number of points in each group.
    - Downsample is done BEFORE taking the convex hull to get a much better
      spread of data that is more evenly spread along the edge.

26/04/20
    Have spent the last couple of weeks putting together a first draft of the
    final report. While writing a number of improvements were discovered when
    generating plots:
    - An eigenvector approach for corner fitting was finally found inspired by
      ICP solutions that remove the mean from the data. Largely it produces the
      same results apart from on the reference models where the lines cross the
      origin, in such cases the results are much better.
    - The implementations of ICP have had their exit conditions changed based
      on a convergence in the cost function, this generally results in an
      earlier exit and as a result faster matches.
    - An initial look into model statistics has yielded some useful results as
      well as a potential framework for decision making within a game based on
      changes in potential damage.

    A pause is being put on the report draft to look into LOS an silhouettes as
    a method for reliably producing these may be found. Currently the report is
    at 29 pages, but missing a number of figures.

27/04/20
    Outline algorithm not work anywhere near as easily as thought. Looking into
    back-face culling and then finding all lines only on one triangle.

    The process is easy to carry out but creates a number of separate lines
    which then need to be grouped. Due to this additional step and the time
    already spent trying to get an algorithm for outline determination working
    the algorithm is abandoned.

    Articles on show/hidden surface determination point at possibly useful
    methods such as ray-casting. Have found a way of getting slices of a mesh at
    different angles, and then can do more details ray casting in each slice

28/04/20
    Taken slices and worked out which are visible from the camera centre.
    Currently it only calculates the node on the line rather than clipping the
    line itself where the occlusion starts at the intersection between two
    points. Results are still satisfactory with detailed enough meshes.
